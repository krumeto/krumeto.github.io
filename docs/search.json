[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Krum Arnaudov",
    "section": "",
    "text": "Reading list\n\n\n\nreadings\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\nKrum Arnaudov\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nmisc\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\nKrum Arnaudov\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Well, I will try blogging. I should have done this years ago, as with many other things, but better late than never.\nI am trying to learn more ‘software-y’ aspects of the ML/DS world. This will help. This blog is built with quarto. Clever people like Hamel have built theirs using it. I am giving it a try as well. It worked (relatively) easily. I know enough markdown for this to be an easy starting path. The best lesson learnt so far - creating a website involves as much copying other great examples, as any other software activity. Need to learn more of the .css/.nojekyll elements. I will - in time. For now, this is good enough.\nI intend to write mostly short “today I learned” or (TIL) posts. I learned about TILs from Vincent Warmerdam, who in turn has mentioned hearing about the idea from Simon Willison. I find it quite convenient. It gets you in the habit of writing down your thoughts, but in smaller bits. Trains you for long form posts. Helps with building a library of ideas/learnings.\nI will also maintain an active Reading List. I currently have a repo on the topic, but an editable blog post seems more elegant."
  },
  {
    "objectID": "posts/reading_list/index.html",
    "href": "posts/reading_list/index.html",
    "title": "Reading list",
    "section": "",
    "text": "This will be an active reading list of videos, books, posts and more generally, anything that I intend to read. Some day.\n\nThe missing semester MIT - https://missing.csail.mit.edu/\nFASTApi live coding - https://www.youtube.com/watch?v=_BZGtifh_gw&ab_channel=DeepLearningAI\nCreate your blog with Quarto - https://www.youtube.com/watch?v=xtSFXtDf4cM&ab_channel=PositPBC\nHamel and Radek on Quarto - https://www.youtube.com/watch?v=IqB-zVc5NgI&feature=youtu.be\nLater in the year, either Statistical Rethinking 2023 (again), BayesRules! or Regression and other stories.\nNLP with Transformers (in progress)\nPytorch learning:\n\nPatrick’s Pytorch course - https://www.youtube.com/watch?v=EMXfZB8FVUA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=1&ab_channel=PatrickLoeber\nhttps://www.learnpytorch.io/\n\nNils Reimers: Sentence Transformers, Search, Future of NLP | Learning from Machine Learning #3 - https://www.youtube.com/watch?v=jOj4d3JNBDU&ab_channel=LearningfromMachineLearning\n\nSimilar - with James Briggs - https://www.youtube.com/watch?v=Bzf1Xh3CLEM&ab_channel=Cohere with\n\nOn the new pandas internals - https://www.youtube.com/watch?v=jIbYomIcl34&ab_channel=PyData\nPosts on creating a search + Q&A:\n\nSimon’s post with GTR-T5-Large - https://til.simonwillison.net/python/gtr-t5-large\nSimon’s wrapper over openAI’s API - https://til.simonwillison.net/gpt3/chatgpt-api\nHamel’s post - https://github.com/hamelsmu/chat-langchain/\nOpenAI’s notebook - https://github.com/openai/openai-cookbook\nSentence Transformers Example - https://www.sbert.net/examples/applications/semantic-search/README.html#examples"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Krum Arnaudov",
    "section": "",
    "text": "My current job is to continuously learn and know as much as possible about LLMs and AI, apply that knowledge to products and features, and consult and advise on all matters related to AI.\nMy skills are an intersection between Machine Learning, NLP (which people call AI nowadays) and Business administration. I am the core AI Architect of Ask FT.\nComfortable with Python, SQL and R. Experience with Google Cloud, AWS, Docker, Cloudera, Power BI, MicroStrategy.\nThroughout my pre-ML career, I’ve done Data Science Consulting, Operations management, Process improvement, Key account management, Quality management, Coaching and Customer Support for living. I am in my wheelhouse building trust with customers and stakeholders, managing change and nurturing teams.\n\n2018 – HP CS President Leading the Way Global Award\n\n2019 – HP Amaze Global Award for “amazing contributions in both business impact and culture”\n\nHappily married, proud father and husband.\n\n\n\n\n\nAsk FT is a generative-AI assistant that answers subscriber questions by synthesising two decades of FT journalism. It started as a simple demo (using semantic search and Falcon 7B), and reached millions of FT’s Professional subscribers.\n\nDesigned a query decomposition and rephrasing pipeline that balances speed with retrieval accuracy, running parallel searches when needed, while infusing knowledge of recent events prior to the search\nThrough extensive prompt engineering, aligned answers to FT’s strict requirements, balancing safety with answer helpfulness\nDesigned a custom moderation layer to fit the FT’s requirements, balancing blocking rate with false positives rate\nContinuously monitored system quality and user feedback, planned future features and initiated incremental improvements\n\nIn addition to FT’s coverage, featured in The Verge, Voicebot.ai, banker.bg and others.\n\n\n\nFT Geopolitical risk level classifier (2025) [setfit, custom annotation] - Finetuned a custom language model for geopolitical risk classification on FT articles, aligning with FT content definitions.\nFT’s embeddings model quality assessment benchmark (2024) [SentenceTransformers, custom dataset creation] - Led an effort to benchmark and assess various text embedding models on FT data.\nFT Macro Themes classification (2024) [setfit, custom annotation] - Finetuned a custom language model for classification of topics of high interest to macro investors.\nFT Sentiment classification model (2024) [setfit, custom annotation] - Finetuned a custom language model for sentiment classification on FT articles, aligning with FT content definitions.\nFT Article Vectorisation (2023) [SentenceTransformers, spaCy, Vetiver, FastAPI] - Transforming article text into numerical vectors to be used in downstream tasks such as semantic similarity, search and others.\nFT Propensity to Renew (2022) [tidymodels, Rstudio Connect] - Building propensity-to-renew models per user cohort for the purposes of marketing campaigns.\nAmplify Analytics Time Series Forecasting for more than 1500+ Series (2021) Forecasting daily patient registrations per patient cohorts for US hospitals.\nAmplify Analytics Novelty Detection using GMM, One-Class SVM and IsolationForest (2020) Novelty Detection of medical claim rejections.\nAmplify Analytics Medical claims outcome classification (2021) Medical claims outcome classification using XGBoost.\n\n\n\n\n\nSEBRA playground mini-package to work with the Bulgarian government opendata SEBRA dataset.\narticlevectorizer package for creating text embeddings with a scikit-learn-style API. Basically, a worse embetter\n\n\n\n\n\nLanguage Models for Real-World Applications - Lessons Learned Link Dev.bg (dev.bg), October 2024\nGoing far with open source tools in NLP Software University (softuni.bg), April 2023\nWhat do we know about chatGPT? FT ML&Data Club, Feb 2023| Slides\nCreating and assessing media article embeddings Sofia Data Science Society, Dec 2022| Github Repo and Slides\nCreating letter embeddings - FT ML&Data Club, Oct 2022| Inspired by Vincent Warmerdam’s video on the same topic\n\n\n\n\nMinor scikit-learn fixes and docs here, here and here\nMinor sktime fix here"
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Krum Arnaudov",
    "section": "",
    "text": "My current job is to continuously learn and know as much as possible about LLMs and AI, apply that knowledge to products and features, and consult and advise on all matters related to AI.\nMy skills are an intersection between Machine Learning, NLP (which people call AI nowadays) and Business administration. I am the core AI Architect of Ask FT.\nComfortable with Python, SQL and R. Experience with Google Cloud, AWS, Docker, Cloudera, Power BI, MicroStrategy.\nThroughout my pre-ML career, I’ve done Data Science Consulting, Operations management, Process improvement, Key account management, Quality management, Coaching and Customer Support for living. I am in my wheelhouse building trust with customers and stakeholders, managing change and nurturing teams.\n\n2018 – HP CS President Leading the Way Global Award\n\n2019 – HP Amaze Global Award for “amazing contributions in both business impact and culture”\n\nHappily married, proud father and husband."
  },
  {
    "objectID": "index.html#flagship-project-ask-ft-financial-times-2023--",
    "href": "index.html#flagship-project-ask-ft-financial-times-2023--",
    "title": "Krum Arnaudov",
    "section": "",
    "text": "Ask FT is a generative-AI assistant that answers subscriber questions by synthesising two decades of FT journalism. It started as a simple demo (using semantic search and Falcon 7B), and reached millions of FT’s Professional subscribers.\n\nDesigned a query decomposition and rephrasing pipeline that balances speed with retrieval accuracy, running parallel searches when needed, while infusing knowledge of recent events prior to the search\nThrough extensive prompt engineering, aligned answers to FT’s strict requirements, balancing safety with answer helpfulness\nDesigned a custom moderation layer to fit the FT’s requirements, balancing blocking rate with false positives rate\nContinuously monitored system quality and user feedback, planned future features and initiated incremental improvements\n\nIn addition to FT’s coverage, featured in The Verge, Voicebot.ai, banker.bg and others.\n\n\n\nFT Geopolitical risk level classifier (2025) [setfit, custom annotation] - Finetuned a custom language model for geopolitical risk classification on FT articles, aligning with FT content definitions.\nFT’s embeddings model quality assessment benchmark (2024) [SentenceTransformers, custom dataset creation] - Led an effort to benchmark and assess various text embedding models on FT data.\nFT Macro Themes classification (2024) [setfit, custom annotation] - Finetuned a custom language model for classification of topics of high interest to macro investors.\nFT Sentiment classification model (2024) [setfit, custom annotation] - Finetuned a custom language model for sentiment classification on FT articles, aligning with FT content definitions.\nFT Article Vectorisation (2023) [SentenceTransformers, spaCy, Vetiver, FastAPI] - Transforming article text into numerical vectors to be used in downstream tasks such as semantic similarity, search and others.\nFT Propensity to Renew (2022) [tidymodels, Rstudio Connect] - Building propensity-to-renew models per user cohort for the purposes of marketing campaigns.\nAmplify Analytics Time Series Forecasting for more than 1500+ Series (2021) Forecasting daily patient registrations per patient cohorts for US hospitals.\nAmplify Analytics Novelty Detection using GMM, One-Class SVM and IsolationForest (2020) Novelty Detection of medical claim rejections.\nAmplify Analytics Medical claims outcome classification (2021) Medical claims outcome classification using XGBoost.\n\n\n\n\n\nSEBRA playground mini-package to work with the Bulgarian government opendata SEBRA dataset.\narticlevectorizer package for creating text embeddings with a scikit-learn-style API. Basically, a worse embetter\n\n\n\n\n\nLanguage Models for Real-World Applications - Lessons Learned Link Dev.bg (dev.bg), October 2024\nGoing far with open source tools in NLP Software University (softuni.bg), April 2023\nWhat do we know about chatGPT? FT ML&Data Club, Feb 2023| Slides\nCreating and assessing media article embeddings Sofia Data Science Society, Dec 2022| Github Repo and Slides\nCreating letter embeddings - FT ML&Data Club, Oct 2022| Inspired by Vincent Warmerdam’s video on the same topic\n\n\n\n\nMinor scikit-learn fixes and docs here, here and here\nMinor sktime fix here"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Krum Arnaudov",
    "section": "",
    "text": "Language Models for Real-World Applications - Lessons Learned\n\n\n\nllm\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nKrum Arnaudov\n\n\n\n\n\n\n\n\n\n\n\n\nData Science in Media - Creating and assessing media article embeddings\n\n\n\nembeddings\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\nKrum Arnaudov\n\n\n\n\n\nNo matching items"
  }
]